1
00:00:14,370 --> 00:00:16,120
对不起 我不在匹兹堡

2
00:00:16,450 --> 00:00:17,880
正如我所说 我来到了西雅图

3
00:00:18,040 --> 00:00:21,520
事实上 我现在就在法院前面

4
00:00:22,410 --> 00:00:25,200
因为光滑的鞋子 男孩三个手指

5
00:00:25,210 --> 00:00:27,400
这个家伙用了鹅

6
00:00:27,810 --> 00:00:31,560
他们去年因使用空头支票而被逮捕

7
00:00:31,570 --> 00:00:34,880
所以他们请我作为他们的品德证人

8
00:00:35,890 --> 00:00:38,080
他们在那里看起来不太好

9
00:00:38,640 --> 00:00:39,790
那是他们的问题 不是我的

10
00:00:39,800 --> 00:00:43,070
所以我想 让我们来这里做课堂演讲

11
00:00:43,240 --> 00:00:44,310
让我们来谈谈数据库

12
00:00:46,560 --> 00:00:48,430
在今天的课上 我们将讨论

13
00:00:49,510 --> 00:00:55,820
在某种程度上 这是对这些现代查询引擎或现代lap

14
00:00:55,830 --> 00:00:57,380
数据库系统在高层次上的概述

15
00:00:57,390 --> 00:01:00,380
这将为我们

16
00:01:00,880 --> 00:01:05,030
在本学期剩下的时间里如何完成各种

17
00:01:05,040 --> 00:01:06,750
主题做好准备

18
00:01:08,160 --> 00:01:10,510
这是我们在本课程中要去的地方的一个高级大纲

19
00:01:10,520 --> 00:01:12,230
我不想在上节课讲这个问题

20
00:01:12,240 --> 00:01:16,720
因为我想花时间谈谈标准

21
00:01:16,730 --> 00:01:18,840
数据库的历史概况

22
00:01:18,850 --> 00:01:22,740
因此 为了理解为什么我们今天关注的

23
00:01:22,750 --> 00:01:24,220
是关系数据库系统

24
00:01:24,710 --> 00:01:29,040
但这是如何构建现代o lab

25
00:01:29,050 --> 00:01:32,680
数据库系统的路线图的高级架构

26
00:01:33,850 --> 00:01:35,880
我们将首先讨论存储

27
00:01:36,220 --> 00:01:39,650
从本质上讲 我们如何在磁盘上表示数据

28
00:01:39,660 --> 00:01:40,650
压缩它

29
00:01:40,660 --> 00:01:46,760
也许可以建立一些索引 我们可以用来加速查询执行

30
00:01:47,610 --> 00:01:52,280
然后 我们将使用所有关于如何存储数据的存储思想

31
00:01:52,520 --> 00:01:57,030
然后花大部分时间讨论我们实际上希望如何对这些数据执行

32
00:01:57,040 --> 00:01:57,750
查询

33
00:01:58,250 --> 00:02:00,800
我们将讨论处理模型和如何调度查询

34
00:02:02,210 --> 00:02:03,480
他们的任务

35
00:02:03,760 --> 00:02:06,380
我们将花很多时间讨论如何执行向量上升

36
00:02:07,070 --> 00:02:12,710
利用Cindy查询编译将是另一个主要主题或方法

37
00:02:12,720 --> 00:02:13,950
我们可以用来加快速度

38
00:02:14,220 --> 00:02:16,970
我们将花很多时间讨论不同的联合算法

39
00:02:17,740 --> 00:02:20,250
今年我们将讨论一些新的东西

40
00:02:20,260 --> 00:02:22,160
我在前几年没有讨论过 那就是物化视图

41
00:02:22,170 --> 00:02:25,240
我必须制作完全物化的视图

42
00:02:25,250 --> 00:02:27,480
这实际上是我所知道的 在数据库系统中最少的

43
00:02:27,490 --> 00:02:29,850
所以我们会花一些时间在这上面

44
00:02:29,860 --> 00:02:31,610
然后我们将讨论查询优化

45
00:02:31,620 --> 00:02:32,810
如何获取查询计划

46
00:02:32,820 --> 00:02:37,250
将其转换为单个查询 生成查询计划

47
00:02:38,490 --> 00:02:40,520
如何设计现代网络接口

48
00:02:40,760 --> 00:02:42,760
在那之后剩下的学期里

49
00:02:43,140 --> 00:02:49,090
我们将对真正的系统进行分析和深刻的反思

50
00:02:49,100 --> 00:02:50,410
比如雪花系统

51
00:02:50,420 --> 00:02:52,060
你们读了今天的报纸

52
00:02:52,870 --> 00:02:58,100
但也有一个大的查询火花和一堆其他的现代系统

53
00:02:58,940 --> 00:03:03,890
这里显示的这种层图与我们在介绍课程中讨论的非常相似

54
00:03:03,900 --> 00:03:05,210
它

55
00:03:05,220 --> 00:03:07,730
本质上是从下往上的系统

56
00:03:07,740 --> 00:03:10,780
您将构建这些不同的抽象接口

57
00:03:11,010 --> 00:03:13,380
他们会有 你会公开一个api

58
00:03:14,250 --> 00:03:18,680
然后我们把它集成到它上面的层

59
00:03:18,690 --> 00:03:22,000
然后到NBN

60
00:03:22,010 --> 00:03:22,960
我们最终将客户端接口暴露给应用程序

61
00:03:24,340 --> 00:03:27,340
在接下来的三节课中

62
00:03:27,350 --> 00:03:30,020
我们将重点关注存储实验

63
00:03:30,660 --> 00:03:34,970
然后 当我们想要运行查询时 这将定义我们实际想要的api

64
00:03:34,980 --> 00:03:36,250
何时向我们公开

65
00:03:38,790 --> 00:03:40,020
今天的执行

66
00:03:40,030 --> 00:03:46,440
正如我所说 这是对现代重叠系统的一个高层次的概述

67
00:03:47,630 --> 00:03:48,580
所以我们不会太深入

68
00:03:48,590 --> 00:03:49,980
比如 你做的算法是什么

69
00:03:49,990 --> 00:03:51,900
修复稍后也会出现的查询

70
00:03:53,510 --> 00:03:56,100
这门课不一定是关于分布式数据库的

71
00:03:56,110 --> 00:04:01,570
因为我想花时间讨论在单个节点上

72
00:04:01,580 --> 00:04:04,770
处理数据的现代技术是什么

73
00:04:04,950 --> 00:04:09,790
然后我们将在分布式架构的基础上进行分层

74
00:04:09,800 --> 00:04:12,980
但最好了解一下现代插座系统

75
00:04:12,990 --> 00:04:15,510
应该是什么样子的

76
00:04:16,060 --> 00:04:19,050
所以明白大鱼不见了

77
00:04:19,060 --> 00:04:22,490
但它确实是以前说过的 还有很多其他的课

78
00:04:23,000 --> 00:04:26,550
首先

79
00:04:26,560 --> 00:04:28,030
我们需要让单节点系统具有高性能和超级优化

80
00:04:28,330 --> 00:04:29,760
在我们使它成为分布式之前

81
00:04:30,090 --> 00:04:32,040
就像使数据库成为分布式一样

82
00:04:32,050 --> 00:04:34,920
这不是魔棒或神奇的解决方案吗

83
00:04:35,080 --> 00:04:36,910
这解决了所有可扩展的问题

84
00:04:36,920 --> 00:04:39,990
就像如果你有一个蹩脚的单节点系统

85
00:04:40,000 --> 00:04:41,550
那么分布式就意味着你有一个蹩脚的多节点系统

86
00:04:42,550 --> 00:04:43,660
我们得先把它跪下来

87
00:04:43,670 --> 00:04:45,610
我想在最后花

88
00:04:45,620 --> 00:04:51,450
一点时间谈谈这个更大的趋势

89
00:04:51,940 --> 00:04:53,810
关于这些olap系统的组件的商业化

90
00:04:53,820 --> 00:04:57,930
所以我们主要谈论的是像雪花和spark这样的系统

91
00:04:58,870 --> 00:05:03,180
它们是供应商已经实现了所有

92
00:05:03,190 --> 00:05:05,460
零碎功能的整体系统

93
00:05:05,700 --> 00:05:09,110
但现在有一种趋势

94
00:05:09,120 --> 00:05:13,070
人们试图构建我之前展示的层图的独立部分

95
00:05:13,080 --> 00:05:14,390
从理论上讲

96
00:05:14,400 --> 00:05:16,790
人们可以把这些东西联系在一起

97
00:05:17,220 --> 00:05:19,450
稍后

98
00:05:19,460 --> 00:05:21,430
我希望新的整个实验室系统

99
00:05:21,440 --> 00:05:22,790
但我们还没有完全做到这一点

100
00:05:23,600 --> 00:05:26,150
但我将谈论这个领域的一些早期工作

101
00:05:31,020 --> 00:05:35,750
首先 我要了解什么是分布式查询

102
00:05:35,760 --> 00:05:37,950
分布式查询的执行是什么样子的

103
00:05:39,270 --> 00:05:41,860
分布式数据库系统中的OLED查询是什么样子的

104
00:05:42,310 --> 00:05:43,830
我要说的是 在高层次上

105
00:05:43,840 --> 00:05:46,350
它本质上与你在单一系统中所拥有的是一样的

106
00:05:47,000 --> 00:05:47,160
对的

107
00:05:47,170 --> 00:05:51,100
当您通过解析器 绑定器

108
00:05:51,110 --> 00:05:55,060
优化器等运行时 sql查询会显示出来

109
00:05:55,360 --> 00:06:00,110
它将生成物理操作符的有向无环图

110
00:06:00,500 --> 00:06:04,810
其中您可以扫描和连接这些物理操作符的实现

111
00:06:05,130 --> 00:06:09,840
它们从它的子运算符中获取一些输入

112
00:06:10,210 --> 00:06:11,820
对它们进行一些计算

113
00:06:11,830 --> 00:06:19,600
然后将其传递给它的父运算符

114
00:06:20,780 --> 00:06:26,940
事实上 这些操作符可以在多个节点上被排除

115
00:06:27,310 --> 00:06:30,390
而不是在单个盒子

116
00:06:30,400 --> 00:06:31,110
单个节点上运行

117
00:06:31,810 --> 00:06:32,890
在更高的地方

118
00:06:32,900 --> 00:06:34,970
再一次 真的没有任何区别

119
00:06:38,390 --> 00:06:40,300
还有任务的编排等等

120
00:06:40,310 --> 00:06:41,820
但这超出了我们今天在这里

121
00:06:41,830 --> 00:06:42,940
讨论的范围

122
00:06:43,150 --> 00:06:44,580
就像白天一样 有一个查询计划

123
00:06:44,590 --> 00:06:46,140
我们把它分解成任务

124
00:06:46,150 --> 00:06:47,420
在节点之间重新分配

125
00:06:47,430 --> 00:06:49,580
这与采用查询计划

126
00:06:49,590 --> 00:06:55,920
分解任务并在多CPU机器上的核心之间分布没有什么不同

127
00:06:57,240 --> 00:07:00,270
我们之前所有的操作符 一个单一节点系统

128
00:07:00,280 --> 00:07:01,990
table扫描 连接和聚合排序

129
00:07:02,220 --> 00:07:06,970
所有这些都存在于一个系统中

130
00:07:08,240 --> 00:07:09,870
在高层次上 它会看这个 对吗

131
00:07:10,040 --> 00:07:13,270
比如说会有一个工人节点的概念

132
00:07:13,800 --> 00:07:17,010
工人将拥有ACPU 它将拥有本地内存

133
00:07:17,020 --> 00:07:18,210
它将有本地磁盘

134
00:07:18,680 --> 00:07:20,340
比如说

135
00:07:20,350 --> 00:07:22,620
如果我们在图中从左到右

136
00:07:22,630 --> 00:07:23,940
我们试图执行一个查询

137
00:07:24,380 --> 00:07:29,170
这些节点中的每一个都负责在为给定

138
00:07:29,180 --> 00:07:31,810
任务分配的操作符进行一些

139
00:07:31,820 --> 00:07:32,690
计算时获取一些输入

140
00:07:32,700 --> 00:07:37,560
然后产生输出作为结果

141
00:07:37,570 --> 00:07:42,270
然后返回给客户端或发送给下一个工作节点

142
00:07:42,900 --> 00:07:44,000
假设我们从最开始开始

143
00:07:44,010 --> 00:07:47,500
假设这是查询计划的底部

144
00:07:47,510 --> 00:07:48,580
我们想要读取我们所说的持久数据

145
00:07:49,210 --> 00:07:52,880
持久数据将是数据库中定义的

146
00:07:52,970 --> 00:07:55,440
表的底层两极

147
00:07:55,530 --> 00:07:59,880
这将是一些文件 这些文件将包含数据

148
00:07:59,890 --> 00:08:03,620
我们知道如何根据一些方案信息来解释它们的类型

149
00:08:03,630 --> 00:08:04,300
一个目录

150
00:08:04,770 --> 00:08:08,480
我们知道如何访问它 扫描和做一些事情 对不对

151
00:08:09,010 --> 00:08:12,680
我不会在这个图中显示持久数据是否在工作节点的本地

152
00:08:12,690 --> 00:08:15,540
或者它是某个共享磁盘体系

153
00:08:15,550 --> 00:08:17,860
结构或对象存储

154
00:08:17,870 --> 00:08:18,900
这将涉及到它

155
00:08:19,300 --> 00:08:20,810
这对我们在这里的目的并不重要

156
00:08:21,900 --> 00:08:23,770
同样 我们接受持久数据

157
00:08:23,780 --> 00:08:25,010
我们正在进行某种扫描

158
00:08:25,980 --> 00:08:28,130
并且我们将增加一些中间数据

159
00:08:29,090 --> 00:08:31,640
然后

160
00:08:31,650 --> 00:08:35,830
当您现在需要将此中间数据发送到查询计划的下一阶段时

161
00:08:35,840 --> 00:08:38,550
可以在同一节点或不同节点上

162
00:08:39,600 --> 00:08:45,920
我们可以做到这一点的方法之一是通过所谓的洗牌操作

163
00:08:46,240 --> 00:08:49,610
在我们做了一些操作之后

164
00:08:50,080 --> 00:08:54,430
我们将把这个中间数据传递给另一组节点

165
00:08:54,440 --> 00:08:57,990
这些节点将根据一些哈希键

166
00:08:58,000 --> 00:09:00,870
或一些范围分区来分发结果

167
00:09:02,210 --> 00:09:04,600
然后会有一些其他的工作人员可以

168
00:09:05,090 --> 00:09:06,480
从洗牌笔记中提取数据

169
00:09:07,120 --> 00:09:10,160
现在 我把洗牌节点阶段作为可选的

170
00:09:11,600 --> 00:09:16,420
因为我不认为snowflake 使用这种明确的节点做到这一点

171
00:09:16,430 --> 00:09:17,580
但 gray 和 drummer 能做到这一点

172
00:09:18,840 --> 00:09:23,360
这样的想法主要是在shuffle节点

173
00:09:23,370 --> 00:09:24,280
拥有大量的内存

174
00:09:24,290 --> 00:09:26,480
所以他们试着把所有东西都放在缓存里 而不是在磁盘

175
00:09:26,490 --> 00:09:28,740
这是一种重新分配事物的方式

176
00:09:28,970 --> 00:09:31,120
我在这里还展示了在number shuffle

177
00:09:31,130 --> 00:09:32,720
节点和worker节点之间有一种1

178
00:09:32,730 --> 00:09:36,040
对1的对应关系

179
00:09:36,050 --> 00:09:37,550
不一定需要在这个不同的阶段你可以扇出或扇入

180
00:09:37,560 --> 00:09:41,420
但这只是一种将中间数据从上一阶段传递到下一

181
00:09:41,750 --> 00:09:42,420
阶段的方法

182
00:09:42,430 --> 00:09:46,040
并且如果有必要在一些新的分区游戏上重新分配

183
00:09:46,800 --> 00:09:49,060
则该网络或节点进行额外的计算

184
00:09:49,820 --> 00:09:50,970
它有更多的中间数据

185
00:09:50,980 --> 00:09:53,130
他们说麻烦阶段与否并不重要

186
00:09:53,590 --> 00:09:55,780
但他们说 现在它下降到另一个工作节点

187
00:09:55,790 --> 00:09:59,460
然后由该节点执行数据合并的一些文件最终聚合

188
00:09:59,470 --> 00:10:01,740
以产生应用程序的结果

189
00:10:02,650 --> 00:10:02,920
又

190
00:10:06,260 --> 00:10:08,080
我们在属性系统上执行查询的方式与在单节点系统上执行查询的方式相比

191
00:10:08,330 --> 00:10:08,920
没有什么真正的

192
00:10:08,930 --> 00:10:12,080
彻底的

193
00:10:12,090 --> 00:10:13,400
显著的不同

194
00:10:13,550 --> 00:10:17,640
我们可能不得不花更多的时间进行数据移动

195
00:10:17,650 --> 00:10:21,390
而现在的数据移动实际上并不像过去那样糟糕

196
00:10:22,900 --> 00:10:26,550
层次结构是与网络一起运行的网络是最慢的

197
00:10:26,560 --> 00:10:29,470
从这里读取是最慢的 内存也是

198
00:10:29,480 --> 00:10:31,590
但现在从来没有真正快过

199
00:10:31,960 --> 00:10:34,750
特别是在大等级的情况下 他们加快了速度

200
00:10:36,680 --> 00:10:39,660
你有这些鱼洗牌操作的硬加速

201
00:10:40,030 --> 00:10:41,310
在某些情况下

202
00:10:41,320 --> 00:10:44,040
向网络发送内容实际上比从磁盘读取内容更快

203
00:10:44,570 --> 00:10:48,130
这个洗牌阶段是一件大事

204
00:10:48,490 --> 00:10:52,300
但我想在这里展示的主要内容是持久数据的概念

205
00:10:52,310 --> 00:10:53,110
中间

206
00:10:53,120 --> 00:10:53,650
数据

207
00:10:53,860 --> 00:10:55,820
因为这将取决于或

208
00:10:56,100 --> 00:10:58,430
我们实际上如何处理不同

209
00:10:58,440 --> 00:11:03,070
类型的数据将取决于是否共享磁盘系统的体系结构

210
00:11:05,280 --> 00:11:08,670
持久数据和中间数据之间的分类来自于你们

211
00:11:08,680 --> 00:11:10,470
读过的一篇重要的论文

212
00:11:11,720 --> 00:11:16,190
他们称之为持久数据的数据被称为

213
00:11:16,200 --> 00:11:17,830
数据库的记录源

214
00:11:17,960 --> 00:11:21,860
如果我插入拉出它的一部分

215
00:11:22,390 --> 00:11:25,420
批量 加载一些数据或复制或插入操作

216
00:11:25,740 --> 00:11:33,520
我希望这两个将驻留在这些持久数据中的持久文件中

217
00:11:33,530 --> 00:11:34,640


218
00:11:35,990 --> 00:11:37,220
在现代系统中

219
00:11:37,230 --> 00:11:40,510
我们将假设持久数据文件的持久数据是不可

220
00:11:40,680 --> 00:11:41,630
变的

221
00:11:42,420 --> 00:11:47,780
这与人们设计假设数据系统的方式有很大的不同

222
00:11:47,790 --> 00:11:49,520
数据系统是在过去几年中构建的

223
00:11:49,530 --> 00:11:51,940
因为您假设您正在使用本地磁盘运行

224
00:11:51,950 --> 00:11:53,700
可以根据需要进行读写

225
00:11:53,940 --> 00:11:56,010
但在现代云环境中

226
00:11:57,180 --> 00:11:58,350
我们在对象存储上运行

227
00:11:58,360 --> 00:12:01,230
或者即使您在早期的前身上运行

228
00:12:01,240 --> 00:12:04,980
如HGFS文件系统

229
00:12:05,440 --> 00:12:06,620
其中一些只是附加的

230
00:12:06,630 --> 00:12:09,010
但您不能进行就地更新

231
00:12:09,800 --> 00:12:13,400
所以在现代实验室系统的情况下

232
00:12:13,410 --> 00:12:14,960
他们会假设这些文件是不可变的

233
00:12:14,970 --> 00:12:17,720
他让你支持更新它们

234
00:12:17,730 --> 00:12:21,730
你必须维护某个人来

235
00:12:21,740 --> 00:12:27,270
跟踪某些东西是否被更新的版本覆盖

236
00:12:28,980 --> 00:12:29,900
但我们会谈到这一点

237
00:12:29,910 --> 00:12:31,380
下节课我们将讨论更多内容

238
00:12:31,950 --> 00:12:35,860
然后另一个有趣的部分效应是这些

239
00:12:37,130 --> 00:12:38,650
它们被称为中间数据

240
00:12:38,660 --> 00:12:43,140
这是我们在查询计划中执行的操作符的输出

241
00:12:43,370 --> 00:12:47,760
然后我们需要将其发送到查询计划中的下一个操作符

242
00:12:48,900 --> 00:12:50,890
这实际上可以是大量的数据

243
00:12:50,900 --> 00:12:52,090
在论文的意义上

244
00:12:52,100 --> 00:12:56,290
他们讨论了查询将生成的中间

245
00:12:56,300 --> 00:13:00,000
数据量如何与持久数据读取的数据量有很小

246
00:13:00,010 --> 00:13:01,520
或没有相关性

247
00:13:01,800 --> 00:13:03,710
就像表可以非常非常小

248
00:13:03,720 --> 00:13:05,710
但它们最终仍然会产生大量的中间数据

249
00:13:05,720 --> 00:13:07,870
因为它们正在进行一些计算

250
00:13:08,330 --> 00:13:10,720
或者也可能是 这与执行时间无关

251
00:13:10,730 --> 00:13:12,560
因此 如果查询需要很长时间才能运行

252
00:13:12,570 --> 00:13:15,760
这并不一定意味着它们必须生成大量中间数据

253
00:13:17,610 --> 00:13:25,590
这个动画数据很有趣 因为你需要尽可能快地移动它

254
00:13:25,600 --> 00:13:26,630
但你不必

255
00:13:26,640 --> 00:13:28,910
担心它的持久性

256
00:13:29,520 --> 00:13:31,510
和容错性

257
00:13:31,520 --> 00:13:33,790
因为一旦你完成了查询

258
00:13:34,750 --> 00:13:37,700
下一个阶段就会立即把它扔掉

259
00:13:38,220 --> 00:13:38,350
对的

260
00:13:38,360 --> 00:13:43,180
所以这篇论文讨论了如何在决定磁盘处理数据

261
00:13:43,390 --> 00:13:45,020
和中间数据之间进行

262
00:13:45,030 --> 00:13:45,980
权衡

263
00:13:46,180 --> 00:13:49,800
通常情况下 当你移动中间数据时

264
00:13:49,810 --> 00:13:50,400
你想把它保存在内存中

265
00:13:55,280 --> 00:13:59,320
因此 我们需要讨论在现代超圈系统中

266
00:13:59,330 --> 00:14:01,560
系统架构会是什么样子

267
00:14:02,250 --> 00:14:06,450
有几种方法可以思考这个问题 但在一天结束时

268
00:14:11,000 --> 00:14:13,440
这是它移动数据的方式

269
00:14:14,110 --> 00:14:19,100
有情绪持久数据或开始在持久数据上开始执行

270
00:14:19,110 --> 00:14:20,220
如开始

271
00:14:20,230 --> 00:14:21,340
扫描它

272
00:14:21,350 --> 00:14:23,860
它也将决定它的位置

273
00:14:25,740 --> 00:14:26,930
再一次

274
00:14:26,940 --> 00:14:30,930
在类间 我们讨论这种共享的东西和共享磁盘

275
00:14:30,940 --> 00:14:31,570
或者只是推送查询数据

276
00:14:31,900 --> 00:14:33,050
拉数据 查询

277
00:14:33,060 --> 00:14:36,280
我们把这些东西说成是这些音乐独有的

278
00:14:36,290 --> 00:14:37,280
但事实并非如此

279
00:14:37,290 --> 00:14:43,080
尤其是在现代平台上

280
00:14:43,090 --> 00:14:44,120
系统不会沿着这些线进行划分

281
00:14:44,130 --> 00:14:45,840
他们实际上什么都做一点

282
00:14:47,370 --> 00:14:51,240
我们可以理解这些方法的权衡和应用

283
00:14:52,580 --> 00:14:53,730
第一件事是说

284
00:14:53,740 --> 00:14:56,550
如果我们想要开始读取和处理数据

285
00:14:56,890 --> 00:14:59,160
我们应该如何开始这个过程

286
00:15:00,090 --> 00:15:01,960
然后我们从一个阶段开始

287
00:15:01,970 --> 00:15:03,480
下一个阶段我们有两个操作符

288
00:15:03,780 --> 00:15:05,050
我们怎么换车

289
00:15:05,060 --> 00:15:08,490
或者中间结果我们传递什么

290
00:15:09,530 --> 00:15:09,880
首先

291
00:15:09,890 --> 00:15:12,160
讨论我们如何开始

292
00:15:12,170 --> 00:15:14,040
执行或移动数据

293
00:15:14,050 --> 00:15:14,920
同样 有两种选择

294
00:15:14,930 --> 00:15:17,780
一种是将查询推到数据 另一种是将数据拉到查询

295
00:15:19,610 --> 00:15:21,080
再说一次 这些想法并不新鲜

296
00:15:21,090 --> 00:15:25,320
他们可以追溯到80年代末 90年代初所做的许多工作

297
00:15:25,330 --> 00:15:28,360
以及一些最早的工作 比如并行分布式数据系统架构

298
00:15:28,600 --> 00:15:32,430
以及如何理解这些事情的权衡 我认为

299
00:15:32,440 --> 00:15:33,710
现代的变化

300
00:15:33,720 --> 00:15:36,250
只是因为老实说

301
00:15:36,700 --> 00:15:37,890
港口变得更好了

302
00:15:37,900 --> 00:15:42,180
特别是云服务的激增 就像对象存储

303
00:15:42,430 --> 00:15:46,950
过去的东西可能什么都不共享

304
00:15:46,960 --> 00:15:50,310
并且是我们认为是最好的方法的主导架构

305
00:15:50,320 --> 00:15:50,950


306
00:15:50,960 --> 00:15:52,630
你看 它总是合乎逻辑的

307
00:15:52,640 --> 00:15:55,830
总是推出数据 查询

308
00:15:55,840 --> 00:15:57,590
推出数据所在的计算

309
00:15:57,600 --> 00:16:00,590
但现在在云中并不总是这样

310
00:16:01,920 --> 00:16:02,710
同样

311
00:16:03,000 --> 00:16:07,680
第一件事是我们希望如何启动在数据库或数据上执行

312
00:16:08,130 --> 00:16:09,720
部分查询的过程

313
00:16:10,560 --> 00:16:13,470
第一种方法是将查询推送到数据

314
00:16:13,480 --> 00:16:19,490
这意味着我们希望将尽可能多的计算移动

315
00:16:19,500 --> 00:16:23,230
到数据所在的位置

316
00:16:23,880 --> 00:16:31,710
这里的思维过程是 执行数据所在的查询的某些

317
00:16:31,720 --> 00:16:34,830
部分的成本总是比将

318
00:16:34,840 --> 00:16:39,290
数据传输到其他计算节点的成本低

319
00:16:39,700 --> 00:16:40,850
得多

320
00:16:41,180 --> 00:16:41,810
再一次 考虑一下

321
00:16:41,820 --> 00:16:42,610
我有一张磁盘

322
00:16:42,800 --> 00:16:45,190
在一个节点上 我有另一个节点的计算

323
00:16:45,200 --> 00:16:49,030
我宁愿将查询发送到磁盘上有它所在的磁盘的数据

324
00:16:49,040 --> 00:16:49,830
然后

325
00:16:50,170 --> 00:16:51,490
将其传输出去

326
00:16:52,080 --> 00:16:54,030
因为网络 网络成本太高了

327
00:16:54,040 --> 00:16:58,360
另一种方法是提取查询的数据

328
00:16:59,140 --> 00:17:01,720
这是您所在的位置

329
00:17:02,460 --> 00:17:03,610
也是查询所在的位置

330
00:17:03,620 --> 00:17:05,490
你把它留在那个计算资源上

331
00:17:06,260 --> 00:17:08,290
然后数据需要访问操作员

332
00:17:08,300 --> 00:17:09,770
需要机会访问的数据

333
00:17:10,200 --> 00:17:12,150
你转到了那个节点

334
00:17:14,040 --> 00:17:18,390
在无法运行任何查询的情况下 这可能是必要的

335
00:17:18,400 --> 00:17:20,950
你不能在日期所在的地方做任何计算

336
00:17:21,410 --> 00:17:24,160
如果我有一个远程文件系统

337
00:17:24,170 --> 00:17:27,280
在那里我不能运行任何东西 我只能做获取 设置和删除

338
00:17:27,680 --> 00:17:29,430
你必须从查询中提取数据

339
00:17:31,400 --> 00:17:31,790
正如我所说的

340
00:17:31,800 --> 00:17:36,550
Harbor在最近几年变得更好了

341
00:17:36,560 --> 00:17:41,520
这并不总是支持查询的最佳设计选择

342
00:17:41,530 --> 00:17:45,480
因为现在云系统中的网络非常庞大

343
00:17:47,220 --> 00:17:48,440
另一个有趣的地方是

344
00:17:48,450 --> 00:17:52,740
这些通常都是排他性的

345
00:17:52,750 --> 00:17:56,130
因为有一些云对象存储

346
00:17:56,140 --> 00:18:01,920
你可以将一些计算推送到数据中

347
00:18:01,930 --> 00:18:03,920
即使你不认为你能做到

348
00:18:03,930 --> 00:18:05,680
所以在S3上

349
00:18:05,690 --> 00:18:09,040
他们有这个选择操作符选择操作

350
00:18:09,280 --> 00:18:12,070
在那里你可以做一些看起来像伪Sequel的事情

351
00:18:15,040 --> 00:18:20,800
所以where子句 你可以把它作为一个s3命令发送到

352
00:18:20,810 --> 00:18:23,400
直接在s3中进行一些初始过滤

353
00:18:23,410 --> 00:18:28,010
这样你现在只需要挖掘满足你的where从句

354
00:18:28,020 --> 00:18:30,350
同样 我的想法是做一个选择状态

355
00:18:30,360 --> 00:18:33,720
但我可以将where子句的一部分发送到s3

356
00:18:33,730 --> 00:18:37,640
s3知道如何负面理解csv文件

357
00:18:37,650 --> 00:18:39,200
jason或公共文件 然后进行筛选

358
00:18:39,700 --> 00:18:44,740
只发送回满足它的行中的

359
00:18:44,750 --> 00:18:45,660
结果

360
00:18:46,690 --> 00:18:47,760
这实际上是非常强大的

361
00:18:47,770 --> 00:18:49,880
因为这基本上是推动数据查询

362
00:18:50,330 --> 00:18:51,540
但不是所有的查询

363
00:18:51,550 --> 00:18:55,260
但至少在你可以做一些过滤的地方足够了

364
00:18:57,340 --> 00:18:58,250
我是亚马逊

365
00:18:59,300 --> 00:18:59,730
抱歉

366
00:18:59,740 --> 00:19:04,090
Microsoft Azure Blob Storage有一些非常类似的功能

367
00:19:05,390 --> 00:19:08,270
您可以再次执行一些类似于sql的操作 以执行一些初始过滤

368
00:19:08,280 --> 00:19:10,110
我不知道它们支持什么文件格式

369
00:19:10,120 --> 00:19:12,180
但基本思想是一样的

370
00:19:13,110 --> 00:19:19,400
同样 接下来我们将使用pull查询

371
00:19:19,410 --> 00:19:24,030
将数据拉到查询计划的较低部分的查询中

372
00:19:24,040 --> 00:19:25,790
比如扫描表的访问方法

373
00:19:26,320 --> 00:19:28,890
但之后我们可能真的会推

374
00:19:30,180 --> 00:19:31,870
但是 当我们从中间阶段开始时

375
00:19:31,880 --> 00:19:34,030
它也可能推动数据查询

376
00:19:37,580 --> 00:19:40,010
现在

377
00:19:40,020 --> 00:19:41,490
我们想要讨论用于更好的分布式系统的两种高级方法

378
00:19:41,500 --> 00:19:42,370
再说一次 这些不是

379
00:19:43,900 --> 00:19:45,130
这个其实很漂亮

380
00:19:46,980 --> 00:19:51,120
这是非常严格的 或者说这是系统的一个清晰的二分法

381
00:19:51,130 --> 00:19:51,390
今天的

382
00:19:51,400 --> 00:19:55,500
但是第一种类型的架构是比较传统的

383
00:19:55,510 --> 00:19:59,020
一种人认为分布式系统是一种无共享的系统

384
00:19:59,250 --> 00:20:03,600
这实际上是迈克·斯特恩·布雷克在20世纪80年代创造的一个短语

385
00:20:03,610 --> 00:20:04,800
或术语

386
00:20:04,810 --> 00:20:05,160
再一次 这里的想法是

387
00:20:05,170 --> 00:20:09,410
几十年来

388
00:20:09,420 --> 00:20:12,570
这一直被认为是建立分布式数据系统的更好方法

389
00:20:13,300 --> 00:20:15,520
直到10年前

390
00:20:15,530 --> 00:20:19,600
这里的想法是 每一个都可以有自己的cpu 自己的内存

391
00:20:19,610 --> 00:20:21,200
自己的本地连接磁盘

392
00:20:21,210 --> 00:20:21,320
对的

393
00:20:21,330 --> 00:20:26,440
考虑一下mvme 节点可以相互通信并查看数据库的其他

394
00:20:26,450 --> 00:20:29,560
部分的唯一方法是通过网络发送

395
00:20:29,570 --> 00:20:30,280
消息

396
00:20:31,330 --> 00:20:34,480
比如 如果我在左边的一个节点上运行

397
00:20:34,730 --> 00:20:37,000
而需要访问右边的数据 我就无法窥视

398
00:20:38,050 --> 00:20:38,600
是磁盘

399
00:20:38,610 --> 00:20:40,560
我得去发信息把数据发给我

400
00:20:41,450 --> 00:20:45,620
数据库将被划分成一些跨节点的子集

401
00:20:45,630 --> 00:20:47,100
（有时称为碎片）

402
00:20:47,790 --> 00:20:54,010
其中每个节点将具有表数据库的正确唯一部分

403
00:20:54,020 --> 00:20:54,770
理想情况下

404
00:20:54,780 --> 00:20:59,120
您希望选择一个分区键

405
00:20:59,130 --> 00:20:59,680
以减少您必须执行的数据传输量

406
00:20:59,690 --> 00:21:00,680
当你加入的时候

407
00:21:01,130 --> 00:21:02,560
我们将在下一节课上讨论一下

408
00:21:02,570 --> 00:21:05,200
这在历史上是一个很难解决的问题

409
00:21:06,590 --> 00:21:08,270
但这确实有很大的不同

410
00:21:08,280 --> 00:21:15,530
现在的挑战是 由于存储与计算绑定

411
00:21:15,540 --> 00:21:19,860
如果不引入一个全新的节点

412
00:21:19,870 --> 00:21:22,930
我就无法轻松地在存储端的计算端添加更多容量

413
00:21:23,130 --> 00:21:24,160
现在 如果我带来一个全新的节点

414
00:21:24,170 --> 00:21:26,680
我必须重新分区来移动数据

415
00:21:27,330 --> 00:21:28,440
以平衡这些数据

416
00:21:30,210 --> 00:21:31,920
再一次 我们将讨论它的含义

417
00:21:31,930 --> 00:21:33,080
很抱歉

418
00:21:33,090 --> 00:21:34,480
每一个都是定量的

419
00:21:34,490 --> 00:21:36,960
这是 当我说 我知道这个 我是其中之一

420
00:21:38,210 --> 00:21:38,750
另一件事也是 因为数据被认为是本地的

421
00:21:38,760 --> 00:21:43,390
就像它们本地连接的磁盘一样

422
00:21:44,570 --> 00:21:48,080
传统上 数据库系统将使用它来访问磁盘

423
00:21:48,090 --> 00:21:55,860
就像posix api或nvme一样

424
00:21:56,130 --> 00:21:56,740
它将被系统调用去读取数据 直接访问磁盘

425
00:21:57,190 --> 00:22:00,880
你可以绕过内核

426
00:22:02,220 --> 00:22:04,550
这些故事需要在英特尔的套件中播放

427
00:22:04,970 --> 00:22:05,810
那是一场噩梦

428
00:22:05,820 --> 00:22:07,330
我们稍后再谈这个问题

429
00:22:07,340 --> 00:22:08,640
但通常情况下

430
00:22:08,650 --> 00:22:11,840
您使用posix来对本地磁盘进行读写

431
00:22:12,300 --> 00:22:15,730
如果我需要通过网络发送东西来与另一个节点通信

432
00:22:16,420 --> 00:22:18,740
也可以对它进行完美的调用

433
00:22:20,000 --> 00:22:22,440
另一种运送方式称为共享磁盘

434
00:22:22,450 --> 00:22:24,320
现在有了这个

435
00:22:24,650 --> 00:22:28,760
我们仍然有每一个数据库数据系统节点

436
00:22:28,770 --> 00:22:30,360
它们都有自己的CPU内存和磁盘

437
00:22:30,840 --> 00:22:35,590
但每个节点上的磁盘本质上只是一个缓存

438
00:22:36,060 --> 00:22:40,530
数据库系统的持久数据或持久文件将位于

439
00:22:40,540 --> 00:22:43,370
这个单独的存储层上

440
00:22:44,050 --> 00:22:45,640
在顶部 我们将有计算层

441
00:22:45,650 --> 00:22:47,480
这就是我们要执行查询的地方

442
00:22:47,850 --> 00:22:51,650
它们可以通过网络的网络彼此通信

443
00:22:51,660 --> 00:22:55,050
但是它们的存储基本上用于短暂的数据

444
00:22:55,370 --> 00:22:58,040
或者像snowflake，作为一个write-through cache

445
00:22:58,050 --> 00:23:01,680
或者用于中间数据的保持区域暂存区域

446
00:23:01,890 --> 00:23:04,360
但节点本质上是无状态的

447
00:23:04,370 --> 00:23:05,440
这意味着如果它崩溃

448
00:23:05,450 --> 00:23:07,760
节点的计算层是无状态的 这意味着它崩溃

449
00:23:08,160 --> 00:23:10,670
我们不会丢失数据库

450
00:23:10,680 --> 00:23:13,870
因为它们都存储在这里的存储层

451
00:23:13,880 --> 00:23:17,850
存储本质上看起来就像一个巨大的磁盘

452
00:23:18,780 --> 00:23:20,750
这在对象存储中并不完全正确

453
00:23:20,760 --> 00:23:28,000
但因为您不通过posix api访问它

454
00:23:28,010 --> 00:23:29,360
所以您使用类似于用户空间

455
00:23:29,370 --> 00:23:33,520
云供应商的API或任何对象存储

456
00:23:34,120 --> 00:23:35,680
如果你不在 他们会提供

457
00:23:37,450 --> 00:23:40,400
为什么这很重要 而不是使用posix api

458
00:23:40,410 --> 00:23:43,970
因为如果它posix api 数据库系统是不知道的

459
00:23:47,210 --> 00:23:51,510
可能是数据的不同物理场合

460
00:23:51,520 --> 00:23:54,240
你会有不同的文件传递等等

461
00:23:54,250 --> 00:23:56,970
但就像数据系统一样

462
00:23:58,530 --> 00:23:59,330
它只会看到

463
00:23:59,340 --> 00:24:03,850
这里的一些文件系统ii可以读取和写入

464
00:24:03,860 --> 00:24:05,850
可能不理解或不能向下推

465
00:24:06,650 --> 00:24:09,440
就像我们之前讨论过的过滤中的选择

466
00:24:09,450 --> 00:24:12,150
如果你正在使用使用posix

467
00:24:12,160 --> 00:24:15,010
因为没有办法做 嘿 读这个

468
00:24:15,020 --> 00:24:17,860
但也为我过滤了一些东西并储存在那里

469
00:24:18,380 --> 00:24:19,500
重述这一切

470
00:24:19,590 --> 00:24:21,300
这两个选择我们没有任何共同之处

471
00:24:22,370 --> 00:24:26,490
它的优点和缺点是它可能实现更好的性能

472
00:24:26,500 --> 00:24:31,550
因为每个数据系统节点

473
00:24:31,560 --> 00:24:34,110
如果它只访问本地数据

474
00:24:37,440 --> 00:24:40,250
它的性能会更好

475
00:24:40,260 --> 00:24:42,890
因为节点之间的数据移动可能会更少

476
00:24:42,900 --> 00:24:43,330
对吧

477
00:24:43,730 --> 00:24:51,790
我说的是现代的MVMVME驱动器 有五个或六个PCICpcie

478
00:24:51,800 --> 00:24:53,830
较低的一层是那些相当大的管道

479
00:24:53,840 --> 00:24:55,270
但你可以让你可以得到

480
00:24:55,280 --> 00:24:58,150
但是现代网络也很好

481
00:24:58,160 --> 00:25:03,070
所以传统上

482
00:25:03,080 --> 00:25:03,790
从本地磁盘读取总是比通过网络读取更快

483
00:25:03,800 --> 00:25:05,430
但现在情况并非总是如此

484
00:25:06,490 --> 00:25:10,520
但最大的挑战是更难横向扩展容量

485
00:25:12,460 --> 00:25:14,010
实际上 在上下两个方向

486
00:25:14,020 --> 00:25:17,170
但是我不能添加新的节点而不移动数据来重新

487
00:25:17,180 --> 00:25:18,490
平衡我们参与的事情

488
00:25:18,990 --> 00:25:22,630
如果不对合并做同样的事情 我不能把节点拿走

489
00:25:24,850 --> 00:25:26,160
现在有了一个共享磁盘系统

490
00:25:26,410 --> 00:25:29,640
在云中的现代环境中

491
00:25:30,000 --> 00:25:32,990
能够扩展计算和存储的巨大

492
00:25:33,000 --> 00:25:34,630
优势是独立的

493
00:25:34,910 --> 00:25:38,820
这意味着如果我自己在我的节点上被cpu绑定

494
00:25:38,830 --> 00:25:41,720
那么我可以添加新的计算节点 因为它们是无状态的

495
00:25:41,990 --> 00:25:43,740
我不需要这样做

496
00:25:44,070 --> 00:25:48,620
我不需要移动大量的数据来反弹

497
00:25:48,630 --> 00:25:49,020
雪花

498
00:25:49,030 --> 00:25:53,140
论文再次讨论了如何使用一致的

499
00:25:53,150 --> 00:25:56,530
哈希来更改处理文件的分配

500
00:25:57,540 --> 00:26:04,700
新节点的持久存储层

501
00:26:06,610 --> 00:26:08,520
但那是你在热身

502
00:26:08,730 --> 00:26:11,100
我们在这里讲述的是

503
00:26:11,910 --> 00:26:13,940
这是你开始处理的数据

504
00:26:13,950 --> 00:26:16,660
这并不是说你必须总是把东西从一个笔记复制到另一个笔记

505
00:26:16,800 --> 00:26:17,550
如果你想安全地做到这一点

506
00:26:17,800 --> 00:26:21,030
并且没有任何错误的肯定和否定

507
00:26:21,040 --> 00:26:22,230
你需要使用事务

508
00:26:22,240 --> 00:26:23,470
这有点复杂

509
00:26:26,070 --> 00:26:27,460
另一个很好的优势

510
00:26:27,950 --> 00:26:33,630
这对于那些想要声明他们的服务的数据库系统来说非常

511
00:26:33,640 --> 00:26:34,550
重要

512
00:26:35,200 --> 00:26:40,050
我可以关闭计算层 我不需要的部分

513
00:26:40,060 --> 00:26:43,970
如果我没有退出任何查询 并且数据不会再次消失 我就知道我不需要

514
00:26:44,220 --> 00:26:46,230
在一个没有共享的系统中

515
00:26:46,240 --> 00:26:47,270
因为

516
00:26:47,280 --> 00:26:49,070
计算机与存储相关联

517
00:26:49,080 --> 00:26:50,070
如果我关闭了一台计算机

518
00:26:50,080 --> 00:26:53,440
知道这意味着存储在该节点中的

519
00:26:53,450 --> 00:26:55,480
数据库部分不再可访问

520
00:26:56,090 --> 00:26:58,400
然而 如果我关闭共享磁盘系统中的计算节点

521
00:26:58,960 --> 00:27:03,100
那么其他剩余的节点可以从共享磁盘获取数据

522
00:27:03,110 --> 00:27:03,620
没问题

523
00:27:05,840 --> 00:27:06,950
在一个持久的服务中

524
00:27:07,920 --> 00:27:10,550
这可以产生很大的不同 因为你可以关闭闲置的东西

525
00:27:12,280 --> 00:27:14,990
那么最后一个就是我们讲的劣势

526
00:27:15,490 --> 00:27:18,160
如果我必须撤销没有在计算机节点

527
00:27:18,170 --> 00:27:19,920
本地缓存的持久数据

528
00:27:21,650 --> 00:27:25,610
我必须将其从共享中拉出 只需对存储层进行分层

529
00:27:25,980 --> 00:27:29,880
也许我可以做一些我们在亚马逊或azure上

530
00:27:29,890 --> 00:27:32,120
讨论过的早期过滤

531
00:27:34,260 --> 00:27:35,960
但情况并非总是如此

532
00:27:35,970 --> 00:27:38,760
因为这取决于过滤器实际上想要做什么

533
00:27:38,770 --> 00:27:45,420
就像你不能做另一个新的复杂的拒绝或者在S3上执行AUDF

534
00:27:45,430 --> 00:27:45,540
对吗

535
00:27:45,550 --> 00:27:47,100
他们不会这么做的

536
00:27:48,710 --> 00:27:49,900
我们未来的重点

537
00:27:50,160 --> 00:27:52,430
剩下的学期我们将专注于共享系统

538
00:27:52,440 --> 00:27:54,590
现在 对于我们将要讨论的一些算法

539
00:27:54,600 --> 00:27:57,270
它实际上并不重要 比如联合算法

540
00:27:57,430 --> 00:27:58,110
他们不知道

541
00:27:58,120 --> 00:28:01,110
也不关心是从共享光盘读取还是从无共享系统读取

542
00:28:01,120 --> 00:28:05,710
因为当您实际计算连接时 您已经扫描了表

543
00:28:06,060 --> 00:28:07,650
对吗

544
00:28:07,660 --> 00:28:08,930
并将其输入扫描操作员

545
00:28:08,940 --> 00:28:10,370
所以它来自哪里并不重要

546
00:28:11,490 --> 00:28:13,040
但只是在后台头脑中

547
00:28:13,050 --> 00:28:15,800
要注意我们不应该考虑

548
00:28:16,530 --> 00:28:18,800
如果我在扫描这个表或扫描数据

549
00:28:20,640 --> 00:28:24,190
来自S3或对象存储意味着什么

550
00:28:24,800 --> 00:28:26,350
正如我之前所说的

551
00:28:26,360 --> 00:28:29,500
传统上 在共享体系结构中

552
00:28:29,510 --> 00:28:34,120
假设存储层是初始的

553
00:28:34,130 --> 00:28:36,200
与我的故事有些执着

554
00:28:37,590 --> 00:28:42,030
在本地设备或存储设备或旋钮上 像posits api一样公开

555
00:28:42,040 --> 00:28:44,950
您可以对其进行读取和写入

556
00:28:46,500 --> 00:28:48,900
在像Rural Exeter Data这样的高端系统中

557
00:28:49,230 --> 00:28:51,300
他们确实使用了存储设备

558
00:28:52,600 --> 00:28:53,710
这些架子在找这个

559
00:28:53,720 --> 00:28:54,950
您必须在存储层进行计算

560
00:28:54,960 --> 00:28:58,550
但日常系统知道

561
00:28:58,560 --> 00:29:02,470
它正在与aaa特殊存储设备进行通信

562
00:29:03,230 --> 00:29:04,420
它通过光纤通道传输

563
00:29:04,430 --> 00:29:07,180
不会主动调用来读取数据

564
00:29:07,190 --> 00:29:09,700
它扩展了专有命令

565
00:29:10,100 --> 00:29:14,560
他们实际上可以在这些系统中做一些谓词下推

566
00:29:16,290 --> 00:29:18,680
但是系统 我们要关注的环境 正如我所说的

567
00:29:18,690 --> 00:29:19,680
是对象存储

568
00:29:20,690 --> 00:29:23,000
因为这是每个人围绕云构建这些现代实验室

569
00:29:23,010 --> 00:29:23,760
系统的方式

570
00:29:24,910 --> 00:29:27,870
然后我说它们是无限可扩展的

571
00:29:28,270 --> 00:29:29,170
很明显

572
00:29:29,180 --> 00:29:33,150
把它放在引号里 但只要你的信用卡上有足够的钱

573
00:29:33,240 --> 00:29:34,870
你的账户上就有钱

574
00:29:34,880 --> 00:29:37,430
你可以继续把你想要的数据放在亚马逊的三个和一个本地出口中

575
00:29:37,440 --> 00:29:39,990
为你存储相当高的保证

576
00:29:40,120 --> 00:29:40,870
和耐用性

577
00:29:41,800 --> 00:29:44,390
这对gc ps云存储中的azure来说是疯狂的

578
00:29:44,930 --> 00:29:51,880
因此 您不必再担心配置存储空间

579
00:29:51,890 --> 00:29:54,480
但他必须在自己的前提系统中执行a

580
00:29:54,730 --> 00:29:58,440
你只是不断地把越来越多的数据扔进你的存储层

581
00:30:02,140 --> 00:30:07,680
而且您也不必单独缩放计算层

582
00:30:08,070 --> 00:30:10,040
你只要不断输入更多的数据 事情就会变得很好

583
00:30:13,250 --> 00:30:15,040
这些对象存储它们实际上看起来像什么

584
00:30:17,010 --> 00:30:20,520
他们将向您展示一个非常简单的api

585
00:30:20,530 --> 00:30:21,320
我们讨论了amazon select

586
00:30:21,520 --> 00:30:24,140
但通常 他们将有三个命令put 获取delete

587
00:30:25,650 --> 00:30:28,350
所以发生的是你有这些

588
00:30:29,330 --> 00:30:31,480
你有你的数据 你正在摄取

589
00:30:31,490 --> 00:30:32,960
把你的数据库

590
00:30:32,970 --> 00:30:37,960
你要把它们分解成这些大的不可变的数据块

591
00:30:37,970 --> 00:30:38,880
这些文件

592
00:30:38,890 --> 00:30:42,000
你可以把它们存储在对象存储中

593
00:30:42,390 --> 00:30:47,300
然后你会有一些目录 可以跟踪一些文件

594
00:30:47,310 --> 00:30:49,780
在对象存储中的此位置找到

595
00:30:50,720 --> 00:30:54,580
我们将在下一节课中更多地讨论这些文件的外观

596
00:30:55,550 --> 00:30:56,030
但一般来说

597
00:30:56,040 --> 00:31:00,410
它们将是柱风暴和1公里格式的一些二进制格式

598
00:31:01,340 --> 00:31:05,770
它将使用PAX布局 在每个块中

599
00:31:07,570 --> 00:31:10,640
表的属性将以列的方式分解

600
00:31:10,650 --> 00:31:16,240
但单个逻辑三元组的所有属性都将在该块中找到

601
00:31:16,690 --> 00:31:18,120
这与垂直存储文件和存储数据的方式不同

602
00:31:18,130 --> 00:31:20,920
在垂直存储文件和存储数据的方式中

603
00:31:20,930 --> 00:31:24,280
表中的每一列都有一个单独的文件

604
00:31:24,490 --> 00:31:24,780
使用包

605
00:31:24,790 --> 00:31:28,990
您基本上可以在单个文件中的单个属性中拥有所有数据

606
00:31:29,440 --> 00:31:30,230
会有一个标题

607
00:31:30,240 --> 00:31:31,430
有时

608
00:31:31,440 --> 00:31:36,950
页脚（如第K部分）将包含有关偏移的元数据

609
00:31:36,960 --> 00:31:38,150
当文件中的列开始时

610
00:31:38,420 --> 00:31:42,320
对于每个配置文件可以更改的不同列

611
00:31:42,330 --> 00:31:45,190
使用哪种压缩方案

612
00:31:45,600 --> 00:31:49,390
有时会有预先计算的索引来进行过滤或区域映射

613
00:31:49,400 --> 00:31:51,890
同样 这些内容将在本学期晚些时候介绍

614
00:31:51,900 --> 00:31:54,310
但他会将所有信息存储在文件本身中

615
00:31:55,640 --> 00:31:58,420
现在 当您想要开始访问对象存储中的数据时

616
00:32:01,120 --> 00:32:04,920
您将在另一个存储上发出请求

617
00:32:05,380 --> 00:32:09,150
只是为了检索文件块的头

618
00:32:09,400 --> 00:32:13,700
然后将获得所有关于列的位置以及使用哪种专业

619
00:32:13,710 --> 00:32:15,580
团队的元数据

620
00:32:15,590 --> 00:32:20,420
然后 您可以执行选择性获取

621
00:32:20,430 --> 00:32:21,500
以获取实际需要的数据的字节范围

622
00:32:21,510 --> 00:32:25,950
因此 您不需要从对象存储中引入整个页面或整个块

623
00:32:26,310 --> 00:32:28,500
然后对其进行解析

624
00:32:29,070 --> 00:32:31,780
你可以带一点点进去

625
00:32:31,790 --> 00:32:32,420
弄清楚你需要去哪里得到剩下的部分

626
00:32:33,320 --> 00:32:35,110
已经取回了这个最小的金额

627
00:32:35,120 --> 00:32:37,270
再说一次 这与我们所说的不同

628
00:32:38,270 --> 00:32:42,860
类间的磁盘IO

629
00:32:42,870 --> 00:32:43,380
我们说每页8千字节或4千字节

630
00:32:43,390 --> 00:32:44,500
你去获取整个东西

631
00:32:44,680 --> 00:32:46,320
即使你只需要它的一部分

632
00:32:46,330 --> 00:32:48,790
你可以在这里更聪明一点

633
00:32:48,800 --> 00:32:50,690
因为块更大 你显然不想实现整个块

634
00:32:51,880 --> 00:32:53,990
我认为在雪花中 块的大小是

635
00:32:54,000 --> 00:32:56,390
我认为最低的是50兆

636
00:32:56,400 --> 00:32:57,350
可能会上升到角落 最大值或类似的东西

637
00:32:57,480 --> 00:32:58,390
我看这些不是小块

638
00:32:58,400 --> 00:32:59,030
这些相当大

639
00:32:59,040 --> 00:33:03,420
所以如果你不需要的话 你不需要把整个东西都拿出来

640
00:33:03,430 --> 00:33:06,620
我想提出的一个有趣的系统是黄砖

641
00:33:07,040 --> 00:33:09,350
这实际上是几年前流感大流行期间

642
00:33:09,800 --> 00:33:11,630
他们给我们的演讲中的一张幻灯片

643
00:33:12,440 --> 00:33:16,830
但它展示了他们是如何使用对象存储和s3的

644
00:33:17,950 --> 00:33:20,100
同样 这个体系结构看起来与我已经向您展示的非常相似

645
00:33:20,110 --> 00:33:21,660
你有这些工人节点

646
00:33:22,230 --> 00:33:25,540
他们有这个本地连接的mdmmessd

647
00:33:26,070 --> 00:33:29,850
所以关于yellow brick的有趣之处

648
00:33:29,860 --> 00:33:33,900
在于他们谈到了他们如何尝试使用亚马逊

649
00:33:35,020 --> 00:33:36,210
S三库

650
00:33:36,620 --> 00:33:38,730
Access三库与我们交流

651
00:33:39,170 --> 00:33:41,190
他们发现它超级慢

652
00:33:41,200 --> 00:33:44,010
所以他们写了自己的图书馆

653
00:33:46,050 --> 00:33:49,560
他们使用自定义库而不是Amazons从S3检索相同的数据

654
00:33:49,570 --> 00:33:52,480
从而获得三倍的性能

655
00:33:53,780 --> 00:33:55,930
我提出这个问题只是想说

656
00:33:55,940 --> 00:33:58,650
你不需要 你不需要使用内阁提供给你的任何东西

657
00:33:58,660 --> 00:33:59,810
用于客户端库

658
00:33:59,820 --> 00:34:02,810
您可以编写自己的东西 并可能获得更好的性能

659
00:34:02,820 --> 00:34:04,530
我忘了他们在这里使用的秘密是什么

660
00:34:04,540 --> 00:34:05,530
他们可能在做

661
00:34:07,070 --> 00:34:09,860
您可能正在执行内核绕过以通过光学存储

662
00:34:09,870 --> 00:34:11,180
并且您可以在客户端使用

663
00:34:11,190 --> 00:34:13,540
你不能在服务器端做这件事 因为亚马逊控制着服务器

664
00:34:14,900 --> 00:34:17,330
但他们正在做的另一件很酷的事情是

665
00:34:17,340 --> 00:34:21,860
他们将使用udp

666
00:34:21,870 --> 00:34:26,130
和英特尔dpdk（数据平面开发套件）在不同节点之间进行通信

667
00:34:26,480 --> 00:34:29,780
这是一种在与Nick对话时绕过内核的方法

668
00:34:31,710 --> 00:34:33,500
她不容易使用它

669
00:34:33,510 --> 00:34:33,740
又

670
00:34:33,750 --> 00:34:34,540
我们以后再谈这个

671
00:34:34,550 --> 00:34:35,260
这一切

672
00:34:35,270 --> 00:34:38,380
英特尔目前的生活就像是超级棘手和超级痛苦

673
00:34:39,540 --> 00:34:40,890
我们将在整个学期中讨论这个问题

674
00:34:43,010 --> 00:34:46,040
还有很多其他的东西我们今天不会讨论

675
00:34:46,050 --> 00:34:49,720
但我们会在下个学期开始讨论这些东西

676
00:34:50,080 --> 00:34:51,470
有不同的文件格式

677
00:34:51,480 --> 00:34:53,110
我再次提到了税收布局

678
00:34:53,120 --> 00:34:54,950
但我们将讨论不同的方法

679
00:34:56,100 --> 00:34:57,170
再一次 所有这些都将是非常非常令人沮丧的

680
00:34:57,180 --> 00:34:58,970
因为它是公里存储

681
00:34:59,360 --> 00:35:00,250
谈论下一节课

682
00:35:00,260 --> 00:35:02,980
您实际上如何决定如何对表进行

683
00:35:03,480 --> 00:35:06,980
水平分区并根据值对其进行拆分

684
00:35:06,990 --> 00:35:11,300
因此 您可以最大限度地减少囚犯结果节点之间的数据传输

685
00:35:11,850 --> 00:35:14,820
然后是你如何摄取新数据的整个过程

686
00:35:15,170 --> 00:35:18,900
就像数据库的一大部分 你绝对想把数据放进去

687
00:35:19,890 --> 00:35:24,670
有快速的路径

688
00:35:24,680 --> 00:35:26,910
而不是运行某种像新的批量加载一样快的速度

689
00:35:26,920 --> 00:35:28,790
并尽可能快地进入系统

690
00:35:29,640 --> 00:35:31,470
显然 想要得到更新的关注 删除它

691
00:35:31,480 --> 00:35:32,390
你是怎么处理的

692
00:35:32,400 --> 00:35:33,950
即使文件是不可变的

693
00:35:34,280 --> 00:35:35,900
然后我们不会谈论太多

694
00:35:35,910 --> 00:35:36,620
但这会出现

695
00:35:36,630 --> 00:35:43,530
稍后我们将讨论数据湖 特别是光子和数据库

696
00:35:45,180 --> 00:35:48,320
但是在摩纳哥系统中

697
00:35:48,330 --> 00:35:52,720
您还希望支持人们在s3中拥有现有

698
00:35:52,730 --> 00:35:54,240
文件的能力

699
00:35:55,300 --> 00:35:58,930
他们可以在Party格式中查看

700
00:35:58,940 --> 00:35:59,570
而不必首先将它们批量加载到您的数据系统中

701
00:35:59,580 --> 00:36:01,810
您希望能够直接在现有的文件中进行操作

702
00:36:02,210 --> 00:36:05,400
如何发现这些文件的存在

703
00:36:06,010 --> 00:36:07,290
那你有什么安排

704
00:36:07,600 --> 00:36:09,390
生产力将花一点时间谈论

705
00:36:09,400 --> 00:36:12,980
这意味着 当查询运行时

706
00:36:12,990 --> 00:36:17,940
我们如何动态地进行更改 以更好地利用资源 可能是调配不足或过度调配

707
00:36:17,950 --> 00:36:20,060
任务或工作人员

708
00:36:20,620 --> 00:36:24,490
我们可以对其进行扩展 并在运行过程中进行更改

709
00:36:24,500 --> 00:36:24,730
又

710
00:36:24,940 --> 00:36:26,450
有很多事情我们在这里没有涉及

711
00:36:26,920 --> 00:36:27,510
这很重要

712
00:36:27,520 --> 00:36:29,390
我们将在这学期晚些时候开始

713
00:36:31,720 --> 00:36:35,560
我一开始就谈到了这一点

714
00:36:35,570 --> 00:36:38,160
当我在这里做一个观察时 在雪花的论文中 你们读到

715
00:36:38,440 --> 00:36:40,150
即使它是关于雪花的

716
00:36:40,520 --> 00:36:41,990
他们谈论雪花做某些事情

717
00:36:42,000 --> 00:36:44,310
但他们做了一些重要的观察

718
00:36:44,700 --> 00:36:47,220
再一次 一个整体系统是什么样子的

719
00:36:47,510 --> 00:36:48,700
这就是我让你们读它的原因

720
00:36:49,170 --> 00:36:51,370
但是要.出来的东西

721
00:36:51,730 --> 00:36:55,960
一个像雪花一样的系统 像戏剧一样的系统 像大查询一样的黄砖

722
00:36:57,350 --> 00:36:58,840
比如数据砖块

723
00:36:58,850 --> 00:37:00,840
这些是整体系统

724
00:37:01,210 --> 00:37:05,210
这意味着它们正在构建数据系统所需的所有

725
00:37:05,220 --> 00:37:06,170
组件

726
00:37:11,260 --> 00:37:12,440
这些是整体系统

727
00:37:12,450 --> 00:37:14,440
这意味着它们正在构建您需要构建的所有组件

728
00:37:14,450 --> 00:37:16,720
这完全是在他们的工程师内部

729
00:37:18,930 --> 00:37:22,760
我们这学期要讨论的大多数非学术系统都会有几乎

730
00:37:23,210 --> 00:37:25,040
相同的架构

731
00:37:25,050 --> 00:37:25,320
对吧

732
00:37:25,330 --> 00:37:27,560
你有查询引擎 你有一些存储层

733
00:37:28,020 --> 00:37:32,680
你有一个管弦乐队来移动xe任务

734
00:37:33,010 --> 00:37:33,310
调度程序 某种类型的数据 对吗

735
00:37:33,620 --> 00:37:37,380
他们几乎都在实现同样的事情

736
00:37:38,530 --> 00:37:43,870
这基本上意味着我们有很多人

737
00:37:43,880 --> 00:37:45,390
他们有很多钱的公司

738
00:37:45,880 --> 00:37:50,130
一遍又一遍地编写相同的数据库和软件

739
00:37:50,140 --> 00:37:50,360
对的

740
00:37:50,370 --> 00:37:52,890
他们写同样的东西 做同样的事情

741
00:37:55,290 --> 00:37:59,450
很明显 这是一个巨大的劳动努力

742
00:37:59,880 --> 00:38:07,720
从广义上讲 这样做可能不符合数据库社区的最佳利益

743
00:38:07,730 --> 00:38:09,880
对吗

744
00:38:09,890 --> 00:38:11,760
如果每个人都实现相同的Sequel解析器

745
00:38:13,480 --> 00:38:16,220
推动我们前进的到底是什么

746
00:38:16,230 --> 00:38:16,620
对的

747
00:38:16,910 --> 00:38:21,280
我们最好花更多的时间去做其他更具创新性的事情

748
00:38:21,290 --> 00:38:27,680
所以在过去5年左右的时间里

749
00:38:27,690 --> 00:38:30,730
有一个有趣的发展

750
00:38:30,820 --> 00:38:35,630
你开始看到在自己的源代码委员会或组织中建立各种项目

751
00:38:35,640 --> 00:38:40,160
将现代重叠系统的部分分解为独立的组件

752
00:38:40,430 --> 00:38:43,580
这些组件是开源的

753
00:38:43,590 --> 00:38:45,180
其他人可以在其上进行构建

754
00:38:45,190 --> 00:38:46,580
其他人可以利用

755
00:38:46,590 --> 00:38:53,820
其他人可以在他们自己的新旧实验室系统中重复使用

756
00:38:53,830 --> 00:38:54,220
对的

757
00:38:55,280 --> 00:38:57,180
再一次 这里的想法是每个人都说

758
00:38:57,190 --> 00:38:58,060
每个人

759
00:38:58,070 --> 00:39:01,390
每个人都说同样的事情 这都是系统的冗余部分

760
00:39:02,040 --> 00:39:07,710
让每个人在一件事上一起努力 让它变得非常非常好

761
00:39:07,720 --> 00:39:09,990
每个人都能收获回报

762
00:39:10,000 --> 00:39:11,350
它们有点像Linux 对吧

763
00:39:11,360 --> 00:39:13,690
Linux是

764
00:39:15,260 --> 00:39:19,790
但现在在研究和学术界之外

765
00:39:19,800 --> 00:39:22,350
试图从零开始构建一个新的操作系统并与Linux竞争

766
00:39:22,360 --> 00:39:22,910
这是一种愚蠢或疯狂的行为

767
00:39:23,730 --> 00:39:25,960
在这种潜在的智慧中

768
00:39:25,970 --> 00:39:28,040
每个人都在谈论我们正在使用的Linux

769
00:39:28,050 --> 00:39:29,320
让我们把它做得非常非常好

770
00:39:29,720 --> 00:39:32,100
这并不完全相同 因为操作系统是一项主要任务

771
00:39:32,110 --> 00:39:34,000
而我所说的其他部分要小得多

772
00:39:34,010 --> 00:39:36,260
但想法是一样的

773
00:39:36,560 --> 00:39:36,570
对的

774
00:39:36,580 --> 00:39:42,010
让我们一起工作

775
00:39:42,260 --> 00:39:43,050
而不是让两个人制造做同样事情的相互竞争的部件

776
00:39:43,630 --> 00:39:46,940
你可以在4个类别中看到这一点

777
00:39:47,920 --> 00:39:51,540
你可以看到这是如何与不同的层联系在一起的

778
00:39:51,550 --> 00:39:52,820
我谈到了开始 对吗

779
00:39:53,290 --> 00:39:55,360
人们得到系统目录 查询优化器

780
00:39:55,370 --> 00:39:58,040
这是系统中最难的部分 是我们要处理的文件

781
00:39:58,050 --> 00:40:01,940
所以我想快速浏览一下这些不同的组件

782
00:40:01,950 --> 00:40:03,260
并讨论一下主要的工作

783
00:40:03,270 --> 00:40:08,380
主要的项目

784
00:40:08,390 --> 00:40:11,350
就像我们在学期中讨论的这些不同的引擎和不同的系统一样

785
00:40:11,620 --> 00:40:13,330
他们中的很多人不会使用这些东西

786
00:40:14,460 --> 00:40:18,270
但对他们来说 它们将是潜在的开源替代品

787
00:40:20,280 --> 00:40:23,070
这种将系统分解为可重用组件

788
00:40:23,080 --> 00:40:25,830
或模块化组件的想法并不新鲜

789
00:40:26,510 --> 00:40:31,500
MSR外科的一位著名研究员写了一篇论文

790
00:40:32,030 --> 00:40:32,860
他回到了那里

791
00:40:32,870 --> 00:40:35,700
我认为这就像19年 2000年

792
00:40:35,710 --> 00:40:39,130
我们讨论了他们所谓的风险拨号数据系统

793
00:40:39,140 --> 00:40:39,290
现在

794
00:40:39,820 --> 00:40:43,260
这个论点是建立在如何使这些不同

795
00:40:43,270 --> 00:40:45,380
种类的子组件模块化

796
00:40:45,390 --> 00:40:46,180
可重用

797
00:40:48,930 --> 00:40:51,720
为了更容易地自动调整它们

798
00:40:52,050 --> 00:40:53,280
建立了自主海军系统

799
00:40:53,290 --> 00:40:54,440
但是

800
00:40:54,450 --> 00:40:58,210
再一次

801
00:40:58,220 --> 00:41:02,100
把系统分解成这些可以通过一些标准PI实现的独立层的想法

802
00:41:02,110 --> 00:41:03,220
基本上是他们很久以前谈论这篇论文的人

803
00:41:05,010 --> 00:41:06,600
第一件事是系统目录

804
00:41:08,050 --> 00:41:09,280
同样

805
00:41:09,290 --> 00:41:12,680
我们正在讨论下一个类

806
00:41:12,690 --> 00:41:13,040
但系统目录基本上是数据系统跟踪的注册表

807
00:41:13,390 --> 00:41:14,620
模式是什么样子的

808
00:41:14,630 --> 00:41:15,460
他们有土豆

809
00:41:15,470 --> 00:41:21,280
如果他们在磁盘上的对象存储中有持久文件

810
00:41:21,290 --> 00:41:22,560
他们就会平静下来

811
00:41:22,900 --> 00:41:27,910
所以这种方法基本上是这样的 如果你调用你的人才评估

812
00:41:27,920 --> 00:41:29,390
为你插入数据

813
00:41:29,400 --> 00:41:30,990
比如插入查询或复制命令

814
00:41:31,250 --> 00:41:34,520
那么数据将会维护它的目录

815
00:41:34,530 --> 00:41:35,600
因为它正在交换文件

816
00:41:36,550 --> 00:41:38,380
如果有一个发现过程

817
00:41:38,390 --> 00:41:40,780
就像他们说的 有一堆现有的三个文件

818
00:41:40,790 --> 00:41:43,980
目录需要有一个epi 需要一种方式来告诉这些文件

819
00:41:43,990 --> 00:41:44,340
你要小心它们

820
00:41:44,850 --> 00:41:49,700
现在有几个项目 人们建立这种云目录 本质上

821
00:41:49,710 --> 00:41:52,140
再一次 只是跟踪

822
00:41:52,150 --> 00:41:52,300
存在什么数据

823
00:41:52,310 --> 00:41:54,100
这些文件

824
00:41:55,090 --> 00:41:57,720
中有什么电缆和列

825
00:41:57,970 --> 00:42:01,000
有时会有一些关于其中内容的基本统计信息

826
00:42:01,010 --> 00:42:02,000
但正如我之前所说

827
00:42:02,010 --> 00:42:04,760
统计信息通常存储在文件本身中

828
00:42:06,040 --> 00:42:09,030
可能最著名的一个或为什么使用的是H目录

829
00:42:09,040 --> 00:42:10,870
这来自蜂巢项目

830
00:42:11,900 --> 00:42:13,170
它是蜂巢的一个包装器

831
00:42:13,180 --> 00:42:14,420
元存储

832
00:42:14,430 --> 00:42:16,180
我知道你可以用这个来点燃火花

833
00:42:16,190 --> 00:42:18,300
我认为还有其他一些系统可以利用它

834
00:42:18,680 --> 00:42:18,870
再一次

835
00:42:18,880 --> 00:42:22,000
把它想象成一个跟踪数据库

836
00:42:22,010 --> 00:42:23,720
模式的键值存储

837
00:42:24,030 --> 00:42:25,540
谷歌有自己的数据目录

838
00:42:25,550 --> 00:42:27,300
亚马逊有自己的蓝牛数据俱乐部

839
00:42:27,750 --> 00:42:29,060
他们基本上都在做同样的事情

840
00:42:29,070 --> 00:42:31,020
但H目录实际上是唯一的一个

841
00:42:33,140 --> 00:42:34,060
接下来是查询优化器

842
00:42:34,750 --> 00:42:38,720
所以我们会花几节课来讨论查询优化

843
00:42:38,730 --> 00:42:43,560
但这些只是通用的框架工作

844
00:42:43,570 --> 00:42:47,520
你可以定义启发式或基于成本的搜索规则来进行职业获取

845
00:42:47,530 --> 00:42:51,440
如何利用其中的一些来为你保留SQL查询的部分

846
00:42:51,450 --> 00:42:55,220
但随后它通过转换规则将其转换为逻辑计划

847
00:42:55,230 --> 00:42:58,300
然后运行基于成本的搜索以生成物理计划

848
00:43:01,450 --> 00:43:02,760
构建数据系统最困难的部分

849
00:43:02,770 --> 00:43:05,170
因为存在所有这些极端情况

850
00:43:05,180 --> 00:43:07,010
结果是它们可以应用的所有这些优化规则

851
00:43:07,810 --> 00:43:11,920
处理相关子查询 就像它变得非常混乱 非常快

852
00:43:13,300 --> 00:43:16,380
而不是每个人都建立自己的第一个蹩脚的

853
00:43:16,390 --> 00:43:17,780
启发式优化

854
00:43:17,790 --> 00:43:18,820
每个人都这样做

855
00:43:19,410 --> 00:43:19,760
从理论上讲

856
00:43:19,770 --> 00:43:24,110
你可以有一个基于成本的搜索 这是非常强大的开箱即用

857
00:43:25,390 --> 00:43:27,700
两个节点的含义是阿帕奇

858
00:43:27,710 --> 00:43:29,140
方解石和绿色块状逆戟鲸

859
00:43:29,670 --> 00:43:34,170
方解石是从露西db出来的

860
00:43:34,180 --> 00:43:36,030
露西db是人工智能认为

861
00:43:36,040 --> 00:43:39,550
商业系统 2000年代末失败了

862
00:43:39,560 --> 00:43:40,670
但不知出于什么原因

863
00:43:41,360 --> 00:43:43,550
方解石被提取出来并被重用

864
00:43:44,290 --> 00:43:46,560
作为一个独立的查询优化器 这非常酷

865
00:43:46,570 --> 00:43:50,200
然后绿拇指的人建造了这个叫做奥卡的东西

866
00:43:50,400 --> 00:43:54,450
它被设计为green plum的查询优化器

867
00:43:54,770 --> 00:43:57,200
green plum是一个实验室系统

868
00:43:58,030 --> 00:44:00,990
正如我们上一节课所讨论的 vm ware现在也拥有该系统

869
00:44:02,600 --> 00:44:04,190
但他们也建造了另一个叫做霍克的东西

870
00:44:04,200 --> 00:44:07,600
就像他们在头顶上做的续集

871
00:44:07,610 --> 00:44:10,120
因此

872
00:44:10,130 --> 00:44:10,760
他们试图建立一个可以在两个系统中使用的单一优化框架

873
00:44:10,770 --> 00:44:12,560
我霍克还在

874
00:44:12,570 --> 00:44:13,960
不是人们真的用它

875
00:44:13,970 --> 00:44:16,030
而是青梅也用它

876
00:44:17,390 --> 00:44:20,860
主要是考虑到这个青梅比方解石更不为人所知

877
00:44:20,870 --> 00:44:22,260
它是用C+写的

878
00:44:23,050 --> 00:44:25,360
方解石是用Java编写的

879
00:44:25,370 --> 00:44:28,720
它的用途比使用方解石的系统更多

880
00:44:30,130 --> 00:44:32,320
我不知道哪一个更强大或不喜欢

881
00:44:34,200 --> 00:44:36,470
它们看起来大致相当

882
00:44:38,460 --> 00:44:40,450
然后还有这些源文件格式

883
00:44:40,460 --> 00:44:47,180
实际上 这是一个非常新颖的想法

884
00:44:48,690 --> 00:44:51,400
现代云系统的数量使之成为可能

885
00:44:52,050 --> 00:44:56,120
从历史上看 数据库系统总是使用自己专有的数据格式

886
00:44:56,410 --> 00:44:56,920
对吗

887
00:44:56,930 --> 00:44:59,800
寻找光明 波斯特格雷斯 我的续集 不管你叫它什么

888
00:45:00,110 --> 00:45:01,660
然后 当他们将文件写入桌面时

889
00:45:01,670 --> 00:45:03,260
这是他们专有的二进制格式

890
00:45:03,270 --> 00:45:08,820
就像您不能在我的单个oracle中使用进度数据文件并读取它们一样

891
00:45:10,090 --> 00:45:12,420
duck tv可以读取单灯文件

892
00:45:12,430 --> 00:45:13,380
但它的设计就是为了做到这一点

893
00:45:13,840 --> 00:45:16,960
但你明白我的意思 真正传输数据或能够从一天的

894
00:45:16,970 --> 00:45:20,960
系统中获取数据并重复使用它或在另一天的系统中进行计算的

895
00:45:20,970 --> 00:45:23,800
唯一方法是将其作为acsb或jason文件转储

896
00:45:23,810 --> 00:45:24,120
对吗

897
00:45:27,080 --> 00:45:29,510
在过去的十年年里

898
00:45:29,520 --> 00:45:30,910
有这样一个时刻说 好吧

899
00:45:31,040 --> 00:45:33,780
让我们实际构建这些二进制文件格式

900
00:45:33,790 --> 00:45:34,900
这样我们就不用倾倒了

901
00:45:34,910 --> 00:45:36,860
它类似于基于文本的格式 如Jason

902
00:45:38,060 --> 00:45:40,810
然后我们可以为这些不同的数据库系统构建库

903
00:45:40,820 --> 00:45:42,570
这些库可以非常高效地访问这些东西

904
00:45:43,010 --> 00:45:43,840
对于这些库

905
00:45:43,850 --> 00:45:47,400
假设您是一个迭代器 可以对这些文件中的列进行批处理

906
00:45:47,410 --> 00:45:51,660
你可以做一些选择扫描 比如选择你真正想要的列

907
00:45:53,120 --> 00:45:55,710
他们中的一些人 他们为你做了所有抑郁的事情吗

908
00:45:55,930 --> 00:45:58,200
但是 他们就像这样

909
00:45:58,210 --> 00:46:00,240
查询计划的最低级别是访问方法

910
00:46:01,580 --> 00:46:06,530
所以这可能是六个最广泛的用户是著名的

911
00:46:07,720 --> 00:46:09,390
2013年

912
00:46:09,400 --> 00:46:10,990
有了parquet 有了org 碳数据出来了

913
00:46:11,240 --> 00:46:13,380
拼花地板可能是使用最广泛的一种

914
00:46:13,390 --> 00:46:17,170
这是来自Claudia和Twitter的关于我的格式的压缩专栏

915
00:46:20,110 --> 00:46:22,420
它具有比工作更积极的压缩

916
00:46:24,780 --> 00:46:27,410
它的速度快不快取决于数据的样子

917
00:46:27,420 --> 00:46:29,130
取决于你实际访问它的方式

918
00:46:29,140 --> 00:46:31,250
所以我不能说一个比另一个好 这取决于很多事情

919
00:46:31,260 --> 00:46:32,950
但是在高水平上

920
00:46:34,200 --> 00:46:37,890
它们基本上是等同的 或者来自Facebook的高项目

921
00:46:38,770 --> 00:46:40,360
碳数据来自夏威夷

922
00:46:40,370 --> 00:46:42,320
正如我所说的 我认为在课堂上

923
00:46:42,370 --> 00:46:45,120
我和我以前的一个学生一起工作

924
00:46:45,490 --> 00:46:49,450
他们实际上尝试使用碳数据

925
00:46:49,460 --> 00:46:49,890
而所有的开源库都不能编译

926
00:46:49,900 --> 00:46:50,330
不能工作

927
00:46:50,340 --> 00:46:53,640
所以我不知道夏威夷是否还有其他人使用碳数据

928
00:46:54,580 --> 00:46:58,650
冰山是一个较新的网络电影

929
00:46:58,660 --> 00:47:02,490
我们将在下一节课上看到它 它是一种在拼花文件上进行支持更新和方案演变的方法

930
00:47:02,500 --> 00:47:05,610
这样你就可以做

931
00:47:05,620 --> 00:47:08,490
他们有一个增量存储 你可以做更新

932
00:47:09,160 --> 00:47:12,270
然后应用它们 做聚会文件 再加上读取历史数据

933
00:47:12,670 --> 00:47:16,980
85是来自科学界的一种更古老的数据格式

934
00:47:17,540 --> 00:47:18,930
来自90年代末

935
00:47:18,940 --> 00:47:20,680
这适用于多维数据

936
00:47:22,700 --> 00:47:23,210
同样

937
00:47:23,220 --> 00:47:29,090
我不知道有任何类型的商业数据库系统使用HTF5

938
00:47:29,100 --> 00:47:30,010
HTF5

939
00:47:30,020 --> 00:47:32,130
正如我所说它

940
00:47:32,140 --> 00:47:35,960
主要用于科学计算 科学仪器

941
00:47:35,970 --> 00:47:42,720
然后apache arrow a是一种内存千米格式

942
00:47:42,730 --> 00:47:43,960
它被设计为一种交换格式

943
00:47:43,970 --> 00:47:49,050
用于在进程之间和网络上非常有效地共享数据

944
00:47:49,660 --> 00:47:50,130
再一次

945
00:47:50,980 --> 00:47:52,470
想象它看起来像镶木地板

946
00:47:52,480 --> 00:47:53,910
但它是用于敌人的数据

947
00:47:54,980 --> 00:47:55,970
对于我们这门课

948
00:47:55,980 --> 00:47:59,210
这门课 我们主要关注的是那些看起来像镶木地板和奥卡内罗的东西

949
00:48:00,340 --> 00:48:02,740
然后对于项目一 我们将在下一节课讨论

950
00:48:02,750 --> 00:48:03,890
将建立一个外部数据的工作

951
00:48:03,900 --> 00:48:07,300
它的一部分 看起来像一个停车文件

952
00:48:07,310 --> 00:48:09,420
没有确切的

953
00:48:09,430 --> 00:48:09,980
好吧

954
00:48:11,540 --> 00:48:15,470
最后一个非常有趣的是独立的活检

955
00:48:15,480 --> 00:48:16,630
查询执行

956
00:48:17,170 --> 00:48:19,120
这就是这门课的意义所在

957
00:48:19,130 --> 00:48:20,600
正如我在一开始所展示的

958
00:48:20,610 --> 00:48:23,360
我们花了很多时间讨论如何构建执行引擎

959
00:48:23,490 --> 00:48:24,780
如何执行向量

960
00:48:24,790 --> 00:48:26,400
如何编译代码

961
00:48:26,410 --> 00:48:27,480
如何连接

962
00:48:27,820 --> 00:48:32,930
这并不是最难的部分 他并不总是查询优化器

963
00:48:32,940 --> 00:48:34,170
但这是肯定的部分

964
00:48:34,180 --> 00:48:39,700
就像可以对性能产生巨大的影响

965
00:48:40,050 --> 00:48:41,870
很明显 你的计划信誉下降了

966
00:48:43,040 --> 00:48:43,670
无论如何

967
00:48:43,680 --> 00:48:47,510
你都完蛋了 但在这个速度下 这会有很大的不同

968
00:48:47,520 --> 00:48:52,580
因此 现在正在进行的工作是构建独立的查询引擎 这些引擎是向量

969
00:48:52,590 --> 00:48:54,780
就是我们前面讲的所有的现代技术

970
00:48:55,890 --> 00:48:58,160
同样 只输入物理操作符的DAG

971
00:48:58,170 --> 00:49:01,080
他们需要其他的东西来做调度和访问

972
00:49:01,090 --> 00:49:02,160
获取数据

973
00:49:02,170 --> 00:49:03,520
做说明和做数据

974
00:49:03,890 --> 00:49:04,760
但最终

975
00:49:05,530 --> 00:49:08,040
内核本质上是查询操作符

976
00:49:08,670 --> 00:49:11,340
其中最著名的是Velox

977
00:49:11,910 --> 00:49:16,450
我们将在学期末花时间讨论它

978
00:49:16,760 --> 00:49:18,810
但现在这实际上非常吸引人

979
00:49:18,820 --> 00:49:26,700
因为向量查询执行是使雪花如此出色

980
00:49:26,710 --> 00:49:27,780
如此独特的原因

981
00:49:28,110 --> 00:49:30,120
至少这是让它变得如此独特的起点

982
00:49:30,570 --> 00:49:31,470
十年前

983
00:49:31,980 --> 00:49:32,290
对吧

984
00:49:32,300 --> 00:49:33,250
他们正在建造的

985
00:49:33,260 --> 00:49:34,450
第一个效果上升 数据

986
00:49:35,310 --> 00:49:36,230
使用引擎

987
00:49:37,870 --> 00:49:38,840
现在它变得如此复杂

988
00:49:39,170 --> 00:49:40,880
每个人都有这些单词的向量X执行

989
00:49:40,890 --> 00:49:42,700
但你能走吗

990
00:49:42,710 --> 00:49:43,740
这是一件大事

991
00:49:43,750 --> 00:49:46,460
但现在Facebook正在打造Velox

992
00:49:46,470 --> 00:49:49,700
有来自Arrow和Influence TV的数据融合

993
00:49:49,920 --> 00:49:52,920
英特尔太有民族特色了

994
00:49:54,820 --> 00:49:59,200
所以现在这非常有趣 因为不

995
00:50:00,300 --> 00:50:04,650
facebook将花费大量时间来构建这个执行引擎

996
00:50:04,660 --> 00:50:08,130
任何人都可以来构建一个包裹 并制作下一个雪花

997
00:50:08,140 --> 00:50:10,610
而不必担心编写执行引擎

998
00:50:12,150 --> 00:50:12,500
从本质上讲

999
00:50:12,510 --> 00:50:14,900
这变成了一种商品

1000
00:50:14,910 --> 00:50:16,220
就像使用当今现代技术的向量执行引擎一样

1001
00:50:16,770 --> 00:50:19,320
它不区分一个系统与下一个系统

1002
00:50:19,330 --> 00:50:24,380
现在是不同节点之间的通信

1003
00:50:24,390 --> 00:50:26,060
有点像我们之前讨论的黄皮书

1004
00:50:26,470 --> 00:50:27,750
然后是所有的查询优化器

1005
00:50:28,820 --> 00:50:29,260
是的 我们很好

1006
00:50:29,550 --> 00:50:30,220
好吧

1007
00:50:30,550 --> 00:50:31,820
我的孩子们在里面

1008
00:50:31,830 --> 00:50:33,650
我要去上课了

1009
00:50:34,660 --> 00:50:35,410
我在上课

1010
00:50:35,420 --> 00:50:36,090
我写的是

1011
00:50:38,060 --> 00:50:39,290
我就像另一个人

1012
00:50:39,700 --> 00:50:40,330
他快好了

1013
00:50:41,440 --> 00:50:41,950
他下来了

1014
00:50:42,440 --> 00:50:45,390
我们从联邦调查局得到的不

1015
00:50:46,610 --> 00:50:47,960
就像 好吧

1016
00:50:48,230 --> 00:50:51,080
就像 谢谢

1017
00:50:54,430 --> 00:50:56,220
总之 这是超级迷人的

1018
00:50:56,570 --> 00:50:57,710
我们花了很多时间陪我们

1019
00:50:57,720 --> 00:50:57,990
好吧

1020
00:50:58,000 --> 00:50:58,270
那么

1021
00:51:02,780 --> 00:51:03,010
对的

1022
00:51:03,020 --> 00:51:06,220
所以这应该是一种高级方法

1023
00:51:06,230 --> 00:51:09,020
对查询优化器的高级概述

1024
00:51:10,330 --> 00:51:11,490
同样 正如我所说的

1025
00:51:11,860 --> 00:51:15,530
你在单个节点上构建这些系统的

1026
00:51:15,540 --> 00:51:18,610
方式并不是每个工人都知道如何

1027
00:51:18,620 --> 00:51:20,450
构建单个数据系统

1028
00:51:20,460 --> 00:51:22,970
这将是我们之前讨论的数据移动问题

1029
00:51:22,980 --> 00:51:23,890
同样 假设

1030
00:51:23,900 --> 00:51:26,770
我们从基于云的专家共享磁盘

1031
00:51:26,780 --> 00:51:27,940
中检索数据

1032
00:51:27,950 --> 00:51:30,700
因此 在特别节目的其余部分

1033
00:51:31,280 --> 00:51:35,720
我们将重点关注如何构建我们讨论过的这些不同的组件

1034
00:51:35,730 --> 00:51:36,760
并使用现代技术来制作它们

1035
00:51:36,770 --> 00:51:37,280
对的

1036
00:51:38,790 --> 00:51:40,540
下节课 我们将讨论存储模型

1037
00:51:40,550 --> 00:51:44,340
我们将讨论如何在列本身中表示数据

1038
00:51:44,350 --> 00:51:45,060
即字节

1039
00:51:45,260 --> 00:51:48,930
我做表格定位 然后在系统目录中也做

1040
00:51:48,940 --> 00:51:51,250
所以希望我能处理这些家伙

1041
00:51:51,260 --> 00:51:52,610
忘记他发生了什么事

1042
00:51:53,860 --> 00:51:55,270
希望他们很快就能完成

1043
00:51:56,710 --> 00:52:01,940
然后我会拍摄下一节课 并将其发布到YouTube上

1044
00:52:01,950 --> 00:52:03,700
在下一节课上

1045
00:52:03,710 --> 00:52:05,020
我们将讨论项目一

1046
00:52:05,510 --> 00:52:07,000
嗨 伙计们 晚安

1047
00:52:07,010 --> 00:52:09,080
看 你

1048
00:52:09,090 --> 00:52:09,920
那是我的最爱

1049
00:52:09,930 --> 00:52:10,520
所有这些

1050
00:52:13,220 --> 00:52:13,690
那是什么

1051
00:52:14,360 --> 00:52:19,990
这是st cricket idesi弄得一团糟

1052
00:52:20,000 --> 00:52:22,340
除非我能像ago ice cube那样做

1053
00:52:22,350 --> 00:52:24,740
从g到e到t 它来了

1054
00:52:24,750 --> 00:52:25,980
我玩这个游戏吗

1055
00:52:25,990 --> 00:52:26,940
哪里没有屋顶

1056
00:52:27,150 --> 00:52:30,620
汤米在过道上看到了一群戴着嗡嗡作响的帽子的

1057
00:52:30,630 --> 00:52:31,340
日光族

1058
00:52:31,350 --> 00:52:35,260
当然 我们要在走道上打一拳 来吧

1059
00:52:35,850 --> 00:52:36,560
那是什么

1060
00:52:36,570 --> 00:52:38,440
那就是我在玩那个

1061
00:52:38,450 --> 00:52:42,800
波克和萨普看到了什么 然后问什么是聚会

1062
00:52:43,300 --> 00:52:45,930
通过46包上的12包箱子

1063
00:52:45,940 --> 00:52:47,930
48得到了真实的价格

1064
00:52:48,210 --> 00:52:51,080
我喝水果 但你喝鲍勃12小时

1065
00:52:51,090 --> 00:52:53,080
他们说比尔让你变胖

1066
00:52:53,090 --> 00:52:54,520
但他们说眼睛是直的

1067
00:52:54,530 --> 00:52:56,120
所以这真的不重要
